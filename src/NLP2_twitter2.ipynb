{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here to\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['grid.color'] = 'lightgrey'\n",
    "# docker start sparkbook\n",
    "import pyspark as ps\n",
    "\n",
    "spark = (ps.sql.SparkSession.builder \n",
    "        .master(\"local[6]\") \n",
    "        .appName(\"case study\") \n",
    "        .getOrCreate()\n",
    "        )\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "en_stop = ['au', 'aux', 'avec', 'ca' 'ce', 'ces', 'cest', 'dans', 'de', 'des', \n",
    "           'du', 'elle', 'en', 'et', 'eux', 'il', 'ils', 'je', 'la', \n",
    "           'le', 'les', 'leur', 'lui', 'ma', 'mais', 'me', 'même', \n",
    "           'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', \n",
    "           'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', \n",
    "           'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', \n",
    "           'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', 'à', \n",
    "           'm', 'n', 's', 't', 'y', 'été', 'étée', 'étées', 'étés', \n",
    "           'étant', 'étante', 'étants', 'étantes', 'suis', 'es', 'est', \n",
    "           'sommes', 'êtes', 'sont', 'serai', 'seras', 'sera', 'serons', \n",
    "           'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', \n",
    "           'seraient', 'étais', 'était', 'étions', 'étiez', 'étaient', \n",
    "           'fus', 'fut', 'fûmes', 'fûtes', 'furent', 'sois', 'soit', \n",
    "           'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'fût', \n",
    "           'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', \n",
    "           'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', \n",
    "           'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', \n",
    "           'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', \n",
    "           'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', \n",
    "           'eut', 'eûmes', 'eûtes', 'eurent', 'aie', 'aies', 'ait', \n",
    "           'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'eût', 'eussions',\n",
    "           'eussiez', 'eussent','i', 'me', 'my', 'myself', 'we', 'our', \n",
    "           'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \n",
    "           \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', \n",
    "           'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \n",
    "           \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', \n",
    "           'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \n",
    "           \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', \n",
    "           'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', \n",
    "           'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', \n",
    "           'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', \n",
    "           'with', 'about', 'against', 'between', 'into', 'through', 'during',\n",
    "           'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', \n",
    "           'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', \n",
    "           'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', \n",
    "           'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', \n",
    "           'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', \n",
    "           't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now',\n",
    "           'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \n",
    "           \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", \n",
    "           'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \n",
    "           \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", \n",
    "           'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won',\n",
    "           \"won't\", 'wouldn', \"wouldn't\", 'si']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-26a4f438b332>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf2_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/jovyan/work/Galva/caseStudy/Spark/spark-case-study/peer_extension/tweets.20150430-223406.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# create a temporary table for spark.sql queries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateOrReplaceTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'temp_view2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "df2_json = spark.read.json('/home/jovyan/work/Galva/caseStudy/Spark/spark-case-study/peer_extension/tweets.20150430-223406.json')\n",
    "# create a temporary table for spark.sql queries\n",
    "df.createOrReplaceTempView('temp_view')\n",
    "# Perhaps because its tweets.something.json ???!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[contributors: string, coordinates: struct<coordinates:array<double>,type:string>, created_at: string, entities: struct<hashtags:array<struct<indices:array<bigint>,text:string>>,media:array<struct<display_url:string,expanded_url:string,id:bigint,id_str:string,indices:array<bigint>,media_url:string,media_url_https:string,sizes:struct<large:struct<h:bigint,resize:string,w:bigint>,medium:struct<h:bigint,resize:string,w:bigint>,small:struct<h:bigint,resize:string,w:bigint>,thumb:struct<h:bigint,resize:string,w:bigint>>,source_status_id:bigint,source_status_id_str:string,type:string,url:string>>,symbols:array<struct<indices:array<bigint>,text:string>>,trends:array<string>,urls:array<struct<display_url:string,expanded_url:string,indices:array<bigint>,url:string>>,user_mentions:array<struct<id:bigint,id_str:string,indices:array<bigint>,name:string,screen_name:string>>>, extended_entities: struct<media:array<struct<display_url:string,expanded_url:string,id:bigint,id_str:string,indices:array<bigint>,media_url:string,media_url_https:string,sizes:struct<large:struct<h:bigint,resize:string,w:bigint>,medium:struct<h:bigint,resize:string,w:bigint>,small:struct<h:bigint,resize:string,w:bigint>,thumb:struct<h:bigint,resize:string,w:bigint>>,source_status_id:bigint,source_status_id_str:string,type:string,url:string,video_info:struct<aspect_ratio:array<bigint>,duration_millis:bigint,variants:array<struct<bitrate:bigint,content_type:string,url:string>>>>>>, favorite_count: bigint, favorited: boolean, filter_level: string, geo: struct<coordinates:array<double>,type:string>, id: bigint, id_str: string, in_reply_to_screen_name: string, in_reply_to_status_id: bigint, in_reply_to_status_id_str: string, in_reply_to_user_id: bigint, in_reply_to_user_id_str: string, lang: string, place: struct<bounding_box:struct<coordinates:array<array<array<double>>>,type:string>,country:string,country_code:string,full_name:string,id:string,name:string,place_type:string,url:string>, possibly_sensitive: boolean, retweet_count: bigint, retweeted: boolean, retweeted_status: struct<contributors:string,coordinates:struct<coordinates:array<double>,type:string>,created_at:string,entities:struct<hashtags:array<struct<indices:array<bigint>,text:string>>,media:array<struct<display_url:string,expanded_url:string,id:bigint,id_str:string,indices:array<bigint>,media_url:string,media_url_https:string,sizes:struct<large:struct<h:bigint,resize:string,w:bigint>,medium:struct<h:bigint,resize:string,w:bigint>,small:struct<h:bigint,resize:string,w:bigint>,thumb:struct<h:bigint,resize:string,w:bigint>>,source_status_id:bigint,source_status_id_str:string,type:string,url:string>>,symbols:array<string>,trends:array<string>,urls:array<struct<display_url:string,expanded_url:string,indices:array<bigint>,url:string>>,user_mentions:array<struct<id:bigint,id_str:string,indices:array<bigint>,name:string,screen_name:string>>>,extended_entities:struct<media:array<struct<display_url:string,expanded_url:string,id:bigint,id_str:string,indices:array<bigint>,media_url:string,media_url_https:string,sizes:struct<large:struct<h:bigint,resize:string,w:bigint>,medium:struct<h:bigint,resize:string,w:bigint>,small:struct<h:bigint,resize:string,w:bigint>,thumb:struct<h:bigint,resize:string,w:bigint>>,source_status_id:bigint,source_status_id_str:string,type:string,url:string,video_info:struct<aspect_ratio:array<bigint>,duration_millis:bigint,variants:array<struct<bitrate:bigint,content_type:string,url:string>>>>>>,favorite_count:bigint,favorited:boolean,filter_level:string,geo:struct<coordinates:array<double>,type:string>,id:bigint,id_str:string,in_reply_to_screen_name:string,in_reply_to_status_id:bigint,in_reply_to_status_id_str:string,in_reply_to_user_id:bigint,in_reply_to_user_id_str:string,lang:string,place:struct<bounding_box:struct<coordinates:array<array<array<double>>>,type:string>,country:string,country_code:string,full_name:string,id:string,name:string,place_type:string,url:string>,possibly_sensitive:boolean,retweet_count:bigint,retweeted:boolean,scopes:struct<followers:boolean>,source:string,text:string,truncated:boolean,user:struct<contributors_enabled:boolean,created_at:string,default_profile:boolean,default_profile_image:boolean,description:string,favourites_count:bigint,follow_request_sent:string,followers_count:bigint,following:string,friends_count:bigint,geo_enabled:boolean,id:bigint,id_str:string,is_translator:boolean,lang:string,listed_count:bigint,location:string,name:string,notifications:string,profile_background_color:string,profile_background_image_url:string,profile_background_image_url_https:string,profile_background_tile:boolean,profile_banner_url:string,profile_image_url:string,profile_image_url_https:string,profile_link_color:string,profile_sidebar_border_color:string,profile_sidebar_fill_color:string,profile_text_color:string,profile_use_background_image:boolean,protected:boolean,screen_name:string,statuses_count:bigint,time_zone:string,url:string,utc_offset:bigint,verified:boolean>>, source: string, text: string, timestamp_ms: string, truncated: boolean, user: struct<contributors_enabled:boolean,created_at:string,default_profile:boolean,default_profile_image:boolean,description:string,favourites_count:bigint,follow_request_sent:string,followers_count:bigint,following:string,friends_count:bigint,geo_enabled:boolean,id:bigint,id_str:string,is_translator:boolean,lang:string,listed_count:bigint,location:string,name:string,notifications:string,profile_background_color:string,profile_background_image_url:string,profile_background_image_url_https:string,profile_background_tile:boolean,profile_banner_url:string,profile_image_url:string,profile_image_url_https:string,profile_link_color:string,profile_sidebar_border_color:string,profile_sidebar_fill_color:string,profile_text_color:string,profile_use_background_image:boolean,protected:boolean,screen_name:string,statuses_count:bigint,time_zone:string,url:string,utc_offset:bigint,verified:boolean>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_sql1 = spark.sql('''\n",
    "SELECT lang , text,created_at, possibly_sensitive, quoted_status.favorite_count\n",
    "FROM temp_view\n",
    "WHERE lang = 'en' and possibly_sensitive = \"True\";\n",
    "''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_sql2 = spark.sql('''\n",
    "SELECT lang , text,created_at, possibly_sensitive, quoted_status.retweet_count\n",
    "FROM temp_view\n",
    "WHERE lang = 'en' and possibly_sensitive = \"False\";\n",
    "''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try and search/identify for Porn type text among tweets\n",
    "#among sensitive tweets with lots of re_tweets or likes_ examine more closely \n",
    "###perhaps deep dive among some volume of like_counts or re_tweet count top 5%? \n",
    "nlp_sql1[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function to filter symbols from nlp_sql1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(row):\n",
    "    to_remove = '''!_~^(){}@:'$%\"\\,-[]<>./?;@#&*'''''\n",
    "     \n",
    "    return ''.join([item for item in row if item not in to_remove]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_counts(sql_results):\n",
    "#     '''\n",
    "#     input = spark list_of_rows\n",
    "#     does = cleaning of string\n",
    "#     output= favorites,string\n",
    "#     '''\n",
    "#     countz = {}\n",
    "#     for index,item in enumerate(sql_results):\n",
    "#         clean =clean_text(item[1])\n",
    "#         #print(clean)\n",
    "#         favs = str(item[4])\n",
    "#         countz[index] = (favs,clean)\n",
    "#     #now have a dict of likes/tweet_text\n",
    "#     return countz\n",
    "\n",
    "# countz = get_counts(sql_results = nlp_sql1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countz2 = get_counts(sql_results = nlp_sql2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(countz[109]) -- > ('None', 'new Blackedcom trailer with the gorgeous MBlueEyesXxX \\n\n",
    "                                    # please RT and follow me and Markenna httpstcoNGWSjEZap4')\n",
    "# def clean_http():\n",
    "#     lst = []\n",
    "#     for k,v in countz2.items(): #countz or countz2\n",
    "#         v_ = v[1].split(' ')\n",
    "#         del v_[-1]\n",
    "#         for item in v_:\n",
    "#             lst.append(item)\n",
    "#     return lst\n",
    "# no_http2 = clean_http() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (no_http[2:10]) --> ['Blind', 'Guitarist', 'by', 'Pablo', 'Picasso', 'Futur', 'achat', '😘']\n",
    "#still not able to remove emojies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs for below could could be as follows\n",
    "# 202: ('None', 'so i went to a party tonight amp asked for the new shawns music and they played stitches WELL httpstcoWHoGPRcv3s'), \n",
    "# 203: ('50', '5 millions  httpstcoJGyUNbunZV')\n",
    "\n",
    "def somefunct(x):\n",
    "    word_dict = {}\n",
    "    counter =0\n",
    "\n",
    "    for k,v in x.items():\n",
    "        counter += 1\n",
    "        likez = v[0] \n",
    "        v=list(v[1].split(' ')) #convert text in list of words\n",
    "        #example_output for (v) --> ['The', 'Old', 'Blind', 'Guitarist', 'by', 'Pablo', 'Picasso', 'httpstcoqNxPnN3jI7']\n",
    "\n",
    "        for item in v: # for each word in the list \n",
    "            v_ = [item]\n",
    "            boozl =''\n",
    "            boozl = likez\n",
    "            if boozl == 'None': #workaround for dealing with None strings\n",
    "                likez = 'Nope' \n",
    "            if item not in word_dict:  \n",
    "                if boozl != 'Nope':\n",
    "                    word_dict[item] = list([boozl])\n",
    "            else:\n",
    "                if boozl != 'Nope':\n",
    "                    word_dict[item].append( boozl )\n",
    "    return word_dict\n",
    "\n",
    "somefunct_output = somefunct(countz2)  #countz or countz2\n",
    "\n",
    "# acum=0\n",
    "# for item in somefunct_output.values():\n",
    "#     unravel = len([x for x in item])\n",
    "#     acum+=unravel\n",
    "# print(acum) --> 602 #Count of words <with overlap however 4/26 --> or someother time remove overlap ?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Trying to make a network: each word is a node, each tweet is a node \n",
    "# connections would be links betweet the tweet and the word\n",
    "# Size of node =  number of likes \n",
    "# color of node indicates  = word or tweet (apply hue based on n_times word is used) Dark == more used, light == less used\n",
    "# Edge thickness degress separation ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringz = ' '.join([i for i in no_http])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringz2 = ' '.join([i for i in no_http2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len('😘'))\n",
    "import demoji\n",
    "demoji.download_codes()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Having challenges removing emoji \n",
    "# consulting Stackoverflow https://stackoverflow.com/questions/33404752/removing-emojis-from-a-string-in-python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "\n",
    "# https://stackoverflow.com/a/49146722/330558\n",
    "def remove_emoji(x):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', x)\n",
    "\n",
    " \n",
    "    \n",
    "text2 = remove_emoji(x) # either stringz or stringz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "wordcloud = WordCloud(stopwords=en_stop , \n",
    "                      width=1200, \n",
    "                      height=800, \n",
    "                      min_word_length=3,\n",
    "                      max_words=15).generate(text2)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.savefig('enFAL_cloud_top15.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_http2(x):\n",
    "    lst = []\n",
    "    x_ = x.lower().split(' ')\n",
    "    del x_[-1]\n",
    "    return x_\n",
    "no_http22 = clean_http2(x)\n",
    "print(no_http22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = spark.sql('''\n",
    "SELECT   text \n",
    "FROM temp_view\n",
    "WHERE lang = 'en' and possibly_sensitive = \"True\";\n",
    "''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3 = spark.sql('''\n",
    "SELECT   text \n",
    "FROM temp_view\n",
    "WHERE lang = 'en' and possibly_sensitive = \"False\";\n",
    "''').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to process each row \n",
    "q2[0:10]\n",
    "#Clean each row\n",
    "##lowercase i.lower(), remove emojies remove_emojies() , remove http with clearn_http() , clean with clean_text() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean2(sql_results):\n",
    "    '''\n",
    "    input = spark list_of_rows\n",
    "    does = cleaning of string\n",
    "    output= favorites,string\n",
    "    '''\n",
    "    countz_d = {}\n",
    "    for index,item in enumerate(sql_results):\n",
    "#         if index == 10:\n",
    "#             return countz_d \n",
    "        clean =clean_text(item) # prehaps cast clean to a list,\n",
    "        #clean2 = clean_text(clean) # using clean2 results in keeping screen names, which could be topics?\n",
    "        remove_emoj = remove_emoji(clean)\n",
    "        remove_http = clean_http2(remove_emoj)\n",
    "        remove_http_ =[item for item in remove_http if item != '@']\n",
    "        countz_d[index]=remove_http_ \n",
    "        \n",
    "    return countz_d  \n",
    "\n",
    "cleaned = clean2(sql_results = q2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned2 =clean2(sql_results = q3)\n",
    "\n",
    "d3={}\n",
    "for kk,vv in cleaned2.items():\n",
    "    lst2=[]\n",
    "    for wword in vv:\n",
    "        ww = list(wword) \n",
    "         \n",
    "        if len(ww) > 1 and w[0] != '@':\n",
    "            v_ = clean_text(wword)\n",
    "            lst2.append(v_)\n",
    "        d3[kk]=lst2\n",
    "print(len(d3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd={}\n",
    "for k,v in cleaned.items():\n",
    "    lst=[]\n",
    "    for word in v:\n",
    "        w = list(word) \n",
    "         \n",
    "        if len(w) > 1 and w[0] != '@':\n",
    "            v_ = clean_text(word)\n",
    "            lst.append(v_)\n",
    "        dd[k]=lst\n",
    "print(len(dd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here to LDA is pyspark walkthrough\n",
    "from pyspark.ml.linalg import Vectors, SparseVector\n",
    "from pyspark.ml.clustering import LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmx = spark.createDataFrame([[1, Vectors.dense([0.0, 1.0])],[2, SparseVector(2, {0: 1.0})],], [\"id\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmx.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA(k=2, seed=1, optimizer=\"em\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.setMaxIter(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web Scrapping Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
